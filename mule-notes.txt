CLOUDHUB: It is an IPaas i.e. Integration Platform as a service.
Anypoint Fabric: It is the cloud hub’s backend infrastructure and services to automatically scale deployed Mule applications.
If we want to access runtime details of mule servers, we can use JMX. Since mule is exposing JMX if we want logs to integrated with other third-party systems like Splunk we can integrate them using JMX.
Cloud hub will provide you a worker, it is nothing but one VM on which our mule instance is running.
Old worker is working still the new one gets deployed, so there is 0 down time.

Cluster: Having more than one server working together and understanding each other.
VM can be used for cloud hub but be aware of creating of our own object store. So, in general for cloud hub we use JMS queues like rabbit, active MQ

Proxy: It monitors the traffic, it always looks at a specific target and gets their request and forward to a specific location.
Policy: it is a mechanism for enforcing filters on traffic.

API Gateway: It is a mule runtime responsible for managing proxies and governance. It is a part of mule runtime.
API Manager monitors the applied policies and API Gateway is responsible for policy enforcement. 
Client always access the proxy endpoint that is different from the implementation layer. Proxy checks the policies are met and then forward to implementation layer.
The policies are always set in user interface through a restful call. The policies are communicated to proxy through Anypoint platform agent
An API proxy can be automatically generated using API Manager.
From mule3.8 api gateway runtime and mule runtime are combined into one.
we can still call api implementation directly instead of calling api gateway, this can be overcome by using api gateway cluster inside a DMZ to run api proxy applications or by using Virtual Private Cloud (VPC).

Advantages of API Gateway:
1. Applies runtime policies to enforce governance (rate limiting, throttling, Caching)
2. Controls the traffic
3. Separates API Management from API Implementation concerns.
4. Determines which traffic is authorized to pass through the API to backend services.
5. Logs all transactions, collects and tracks analytics data.

Mule ESB Runtime: Where we deploy our applications. It can be on premise or on cloud. Once we have our application build using studio we can deploy them in ESB runtime.
To manage the applications running in runtime there are 2 solutions 1. MMC, 2. Run time manager
When we start mule run time then mule agent with port no 7777 is configured. Mule agent exposes the run time properties of your mule run time like how much memory is occupied, number of threads running.

To manage on cloud earlier we had cloud hub console and now it is renamed as run time manager. For managing applications on cloud, we use Run time manager.
Once you have the mule runtime either on premise or on cloud. Our mule run time has applications which has some orchestrated flows. We can expose orchestrated flows in application as REST API using API KIT router.

Whenever we are exposing a REST API we may want to manage our API like we want to apply some policies, SLA’s as we want to configure some security to our REST API, there is a component in anypoint platform called API Manager which is cloud based, in this we describe our API using RAML file and this manager develop a proxy for our API.
We can deploy this proxy in a separate runtime called as API Gateway, now the proxy which is generated by API Manager is going to deploy on API Gateway. API Gateway can be on-premise or on-cloud.
Whenever we are exposing REST API to our client we won’t expose the original url which is running inside our runtime, we expose proxy url to the clients.
The client makes call to proxy url which is running inside the gateway and the proxy will call the original application (mule Runtime).

If you want to configure SLA’s policies we don’t need to write code, we want to configure SLA’s and policies on API Manager. 
The API Manager will push the policies to API Gateway and gateway will apply policies for client call. If everything is fine call will go to original API (mule runtime). If conditions are not satisfied, then proxy itself give the responses.

Flow Processing Strategies: All Mule flows have an implicit processing strategy which Mule applies automatically: either synchronous or queued-asynchronous
The Synchronous Flow Processing Strategy: Mule processes messages in a single thread.
The Queued-Asynchronous Flow Processing Strategy: Mule uses a queue to decouple the receiver thread from the rest of the flow. This means that once the receiver places a message into a queue, it can immediately return and accept a new incoming message. Furthermore, each message waiting in the queue can be assigned a different thread from a pool of threads. A component called a Work Manager assigns pending messages to available threads, so they can be processed in parallel. Such parallel processing is ideal for situations where the receiver can, at peak times, accept messages significantly faster than the rest of the flow can process those messages.
However, the increased throughput facilitated by the asynchronous approach comes at the cost of transactional reliability. 
You might want to specify a synchronous flow to achieve reliability. Remember that the synchronous strategy is ideally suited for flows where the flow’s inbound endpoint must be notified of all errors that occur during the processing of the message.

The specific type of queue implemented for the queued-asynchronous flow processing strategy is known as a SEDA queue.
A flow with a queued-asynchronous processing strategy can execute on any node in a cluster. A flow with a synchronous processing strategy executes on the same node of the cluster until processing in the flow is complete.
you can only fine-tune a queued-asynchronous strategy, you can fine-tune it to adjust how it behaves; you cannot do any fine-tuning for a synchronous flow.
You can fine-tune a queued-asynchronous processing strategy by: 1. Changing the number of threads available to the flow. 2. Limiting the number of messages that can be queued. 3.Specifying a queue store to persist data. You achieve this fine-tuning by specifying parameters for a global processing strategy.

Webservice: It is a way for two applications to communicate over a network. These two applications may be any 2 different applications like one is developed by java and other may be by .net.
It uses Interoperable format to transfer the data between applications.
In web service there will be two actors i.e. 1. provider: which application is giving services to other application. 2. Consumer: which application is taking data from other application.
webservice is a specification, they are not providing any API i.e. it is a set of rules and guidelines to communicate two applications. Java acts as both provider and consumer but all doesn’t act as like both ex: android and swift can consume the services but it cannot provide the services.
Difference B/W web application and web services: for web application, client application must be a browser but in case of webservice client application is some other application. 

Web services has suggested some components to use between two applications to share information they are 1. WSDL, 2. UDDI (Universal Description Discovery and Integration), 3. SKELETON, 4. STUB or Proxies, 5. SOAP protocol, 6. HTTP Protocol.
UDDI is not mandatory to use in webservice registry but remaining 5 are mandatory.
Webservice contains the information required to invoke from the client application in the form of XML, it also contains end point URL.
Service provider will store the WSDL file in UDDI Registry software with some unique name and that unique name is shared to the client.
using this WSDL file client generates some classes called STUBS or Proxies using some STUB generation tool. If client application is C++, then STUB is a C++ class and if it is a php then stub is php

After creating stub client will create stub object in client application and on top of stub he will invoke that method by passing the required values, then this method call is going back to STUB. Then the stub will store the details in the form of XML document known as SOAP Request. It contains name of method, parameter values and parameter types.
Stub uses some predefined tags to prepare the xml document and this predefined tag are called SOAP tags, so it is called SOAP request.
Now this SOAP request needs to move from client location to Server location using HTTP protocol. Here the SOAP request contains name of the method, parameter values and parameter types.

The server will receive the request i.e. SOAP request, and this is handover to Skeleton which is present on server side.
Skeleton will invoke the client requested method on the actual service class by passing the parameter values. Then skeleton will get the return value and this return value needs to send to client location.
Skeleton will prepare one xml document known as SOAP response in this it will store the service return value.
This SOAP response is transferred from server location to client location by HTTP protocol.
Now the soap response is available at the client location which contains the return value. This soap response will be read by stub and stub will get the return value and the return value is handover to client.

WSDL: It is an xml file which contains service class details and service provider will prepare this WSDL file. To prepare this WSDL we need WSDL generation tool. Service provider after developing service class he will use WSDL generation tool to prepare the WSDL file. 
The inputs to WSDL generation tools are service class and endpoint URL then it will generate WSDL file. After preparing the WSDL file we need to handover it to Client.
The role of WSDL file in webservice architecture is to understand service details by the client. If already client knows about your service class maybe WSDL file is not required.
UDDI is not mandatory to share WSDL file. The service provider can share the WSDL file by email attachment to client.
If you want your WSDL file to be shared to 1000 of clients, then we need UDDI instead of email attachment.

SOAP Purpose: It is a protocol it contains set of tags, which are used by STUB to prepare the SOAP request and used by skeleton to prepare the SOAP response. 
SOAP is a messaging protocol here i.e. we are preparing messages here on client side and server side.

HTTP Protocol: It is a transportation protocol here because it is moving soap request from client location to server location and soap response from server location to client location.

Skeleton: It is a predefined class. It will get the method details from soap request and it will invokes that client requested method on that service class it will get the return value and that return value is stored in the soap response.

To develop the webservice we need mainly two components. 1. WSDL generation tool, 2. Skeleton class. 
If you develop application using java then sun provides these 2 components, if we use C# Microsoft will provide you the 2 components.

From client side also, the required stub generation tool is provided by sun if we use java and by Microsoft if we use C# for client application.
Sun has provided 4 java webservice API’s. 1. JAX-RPC (Java API for XML- remote Procedure Call), 2. JAX-M (Java API for Xml Messaging), 3. JAX-WS (Java API for XML -Web Services), 4. JAX-RS (Java API for Restful webservices). These API’s should contain WSDL generation tool, skeleton, stub generation tool. 

We can develop synchronous (remaining 3) and asynchronous (JAX-M) webservices using this 4 java API’s.
Whenever client makes a request to webservice and webservice provides immediate response to the client then it is called synchronous web service.
Synchronous web services are divided into 2 types. 1. SOAP (we use JAX-RPC and JAX-WS), 2. Restful webservice (JAX-RS).
All this 4 API’s are specifications i.e. an API that contains only interfaces and abstract classes. They are not providing any implementation classes here.
We cannot use this API’s directly in our service side or client side to develop the webservices because they are the specifications. So instead of specifications we use implementations here

RTF: Runtime Fabrics (docker+kubernetes): MuleSoft’s flexible deployment target that lets you run APIs 𝗼𝗻 𝗮𝗻𝘆 𝗰𝗹𝗼𝘂𝗱 𝗼𝗿 𝗱𝗮𝘁𝗮 𝗰𝗲𝗻𝘁𝗲𝗿 with full control.
	 It is a container service that allows for automated deployments and management in the cloud. Runs on your infrastructure but connects on-prem to cloud. It helps in getting some great features like speed of the cloud with on-premise deployment
	It contains controllers(connecting external world to the application and will use internal load balancer to route to workers) and workers (it will run applications). Default prod env is 3 controller and 3 worker servers
	RTF Capabilities:
	· Application isolation (it will not affect other application running in same server)
	· Capability to run multiple versions of the Mule runtime on the same set of resources 
	· Easily scale applications 
	· Automated application fail-over (keep replicas)
Out of the box management portal with Anypoint Runtime Manager 
 𝗪𝗵𝘆 𝗥𝗧𝗙?
✅ Run APIs in your own cloud (AWS, Azure, GCP, or on-prem)
✅ Maintain 𝘀𝗲𝗰𝘂𝗿𝗶𝘁𝘆 & 𝗰𝗼𝗺𝗽𝗹𝗶𝗮𝗻𝗰𝗲 while scaling easily
✅ Decouple 𝗮𝗽𝗽 𝗵𝗼𝘀𝘁𝗶𝗻𝗴 from 𝗔𝗻𝘆𝗽𝗼𝗶𝗻𝘁 𝗖𝗼𝗻𝘁𝗿𝗼𝗹 𝗣𝗹𝗮𝗻𝗲
✅ Bring 𝗞𝘂𝗯𝗲𝗿𝗻𝗲𝘁𝗲𝘀-𝗹𝗲𝘃𝗲𝗹 𝗼𝗿𝗰𝗵𝗲𝘀𝘁𝗿𝗮𝘁𝗶𝗼𝗻 to MuleSoft

🛡️ 𝗞𝗲𝘆 𝗕𝗲𝘀𝘁 𝗣𝗿𝗮𝗰𝘁𝗶𝗰𝗲𝘀:
🔐 Use 𝗱𝗲𝗱𝗶𝗰𝗮𝘁𝗲𝗱 𝗹𝗼𝗮𝗱 𝗯𝗮𝗹𝗮𝗻𝗰𝗲𝗿𝘀 for isolation
📈 Enable 𝗵𝗼𝗿𝗶𝘇𝗼𝗻𝘁𝗮𝗹 𝘀𝗰𝗮𝗹𝗶𝗻𝗴 for performance
🔒 Configure 𝗧𝗟𝗦 + 𝗠𝘂𝘁𝘂𝗮𝗹 𝗔𝘂𝘁𝗵 on Ingress
📊 Monitor via 𝗔𝗻𝘆𝗽𝗼𝗶𝗻𝘁 𝗠𝗼𝗻𝗶𝘁𝗼𝗿𝗶𝗻𝗴 + 𝗖𝗹𝗼𝘂𝗱𝗪𝗮𝘁𝗰𝗵
🧪 Use 𝘀𝗮𝗻𝗱𝗯𝗼𝘅 𝗳𝗮𝗯𝗿𝗶𝗰 for safe testing

IAM:
Identity and Access Management (IAM) makes sure the right people get access to the right resources at the right time, using things like passwords or other checks to confirm who they are, and setting rules about what they’re allowed to do.

Analogy: Think of it like a bouncer at a club. The bouncer (the IAM system) first checks your ID (authenticates you) to verify you are a valid member, then looks at your ticket or wristband (your permissions) to see which areas you're allowed into—the general dance floor, the VIP lounge, or the private owner's office.

The key concepts in any IAM system are:
	• Authentication: The process of verifying a user's identity. This could be a username/password, a biometric scan, or a token.
	• Authorization: The process of granting or denying access to specific resources based on the authenticated identity.
	• Identity Provider (IdP): A service that creates, maintains, and manages identity information for users. For example, Okta, ForgeRock,Google Identity, AWS cognito or Azure Active Directory.
	• Service Provider (SP): The application or service that a user is trying to access. In this case, that's MuleSoft's Anypoint Platform.
Single Sign-On (SSO): The capability for a user to log in once with their corporate credentials and get authenticated access to multiple applications without re-entering their password. This is what connects the IdP and the SP.

How It Works:
• User wants to log in: An employee goes to the Anypoint Platform login page.
• Redirection to the IdP: Instead of typing a username and password, Anypoint Platform redirects the user's browser to the company's SSO login page (e.g., Okta).
• Authentication at the IdP: The user logs in with their corporate credentials (e.g., using Okta's login screen). The IdP validates the user and generates a SAML assertion (a digitally signed XML document) containing information about the user, such as their email and group memberships.
• Redirection back to the SP: The browser is redirected back to Anypoint Platform, carrying the SAML assertion.
• Anypoint Platform verifies: Anypoint Platform receives the assertion, validates its digital signature using a public key shared by the IdP, and extracts the user information. It doesn't need to know the user's password; it just trusts that the IdP has already verified them.
• Authorization and Login: Based on the user's email and groups from the assertion, Anypoint Platform maps them to a specific user and grants them access with the appropriate permissions (e.g., "Anypoint Platform Administrator" or "API Developer").

What’s the difference between SAML, OAuth2, and OIDC in IAM?
“SAML is XML-based, mainly for web SSO. OAuth2 is for delegated authorization using tokens. OIDC extends OAuth2 to add identity — so you know who the user is, not just that they’re authorized.”

