CLOUDHUB: It is an IPaas i.e. Integration Platform as a service.
Anypoint Fabric: It is the cloud hub’s backend infrastructure and services to automatically scale deployed Mule applications.
If we want to access runtime details of mule servers, we can use JMX. Since mule is exposing JMX if we want logs to integrated with other third-party systems like Splunk we can integrate them using JMX.
Cloud hub will provide you a worker, it is nothing but one VM on which our mule instance is running.
Old worker is working still the new one gets deployed, so there is 0 down time.

Cluster: Having more than one server working together and understanding each other.
VM can be used for cloud hub but be aware of creating of our own object store. So, in general for cloud hub we use JMS queues like rabbit, active MQ

Proxy: It monitors the traffic, it always looks at a specific target and gets their request and forward to a specific location.
Policy: it is a mechanism for enforcing filters on traffic.

API Gateway: It is a mule runtime responsible for managing proxies and governance. It is a part of mule runtime.
API Manager monitors the applied policies and API Gateway is responsible for policy enforcement. 
Client always access the proxy endpoint that is different from the implementation layer. Proxy checks the policies are met and then forward to implementation layer.
The policies are always set in user interface through a restful call. The policies are communicated to proxy through Anypoint platform agent
An API proxy can be automatically generated using API Manager.
From mule3.8 api gateway runtime and mule runtime are combined into one.
we can still call api implementation directly instead of calling api gateway, this can be overcome by using api gateway cluster inside a DMZ to run api proxy applications or by using Virtual Private Cloud (VPC).

Advantages of API Gateway:
1. Applies runtime policies to enforce governance (rate limiting, throttling, Caching)
2. Controls the traffic
3. Separates API Management from API Implementation concerns.
4. Determines which traffic is authorized to pass through the API to backend services.
5. Logs all transactions, collects and tracks analytics data.

Mule ESB Runtime: Where we deploy our applications. It can be on premise or on cloud. Once we have our application build using studio we can deploy them in ESB runtime.
To manage the applications running in runtime there are 2 solutions 1. MMC, 2. Run time manager
When we start mule run time then mule agent with port no 7777 is configured. Mule agent exposes the run time properties of your mule run time like how much memory is occupied, number of threads running.

To manage on cloud earlier we had cloud hub console and now it is renamed as run time manager. For managing applications on cloud, we use Run time manager.
Once you have the mule runtime either on premise or on cloud. Our mule run time has applications which has some orchestrated flows. We can expose orchestrated flows in application as REST API using API KIT router.

Whenever we are exposing a REST API we may want to manage our API like we want to apply some policies, SLA’s as we want to configure some security to our REST API, there is a component in anypoint platform called API Manager which is cloud based, in this we describe our API using RAML file and this manager develop a proxy for our API.
We can deploy this proxy in a separate runtime called as API Gateway, now the proxy which is generated by API Manager is going to deploy on API Gateway. API Gateway can be on-premise or on-cloud.
Whenever we are exposing REST API to our client we won’t expose the original url which is running inside our runtime, we expose proxy url to the clients.
The client makes call to proxy url which is running inside the gateway and the proxy will call the original application (mule Runtime).

If you want to configure SLA’s policies we don’t need to write code, we want to configure SLA’s and policies on API Manager. 
The API Manager will push the policies to API Gateway and gateway will apply policies for client call. If everything is fine call will go to original API (mule runtime). If conditions are not satisfied, then proxy itself give the responses.

Flow Processing Strategies: All Mule flows have an implicit processing strategy which Mule applies automatically: either synchronous or queued-asynchronous
The Synchronous Flow Processing Strategy: Mule processes messages in a single thread.
The Queued-Asynchronous Flow Processing Strategy: Mule uses a queue to decouple the receiver thread from the rest of the flow. This means that once the receiver places a message into a queue, it can immediately return and accept a new incoming message. Furthermore, each message waiting in the queue can be assigned a different thread from a pool of threads. A component called a Work Manager assigns pending messages to available threads, so they can be processed in parallel. Such parallel processing is ideal for situations where the receiver can, at peak times, accept messages significantly faster than the rest of the flow can process those messages.
However, the increased throughput facilitated by the asynchronous approach comes at the cost of transactional reliability. 
You might want to specify a synchronous flow to achieve reliability. Remember that the synchronous strategy is ideally suited for flows where the flow’s inbound endpoint must be notified of all errors that occur during the processing of the message.

The specific type of queue implemented for the queued-asynchronous flow processing strategy is known as a SEDA queue.
A flow with a queued-asynchronous processing strategy can execute on any node in a cluster. A flow with a synchronous processing strategy executes on the same node of the cluster until processing in the flow is complete.
you can only fine-tune a queued-asynchronous strategy, you can fine-tune it to adjust how it behaves; you cannot do any fine-tuning for a synchronous flow.
You can fine-tune a queued-asynchronous processing strategy by: 1. Changing the number of threads available to the flow. 2. Limiting the number of messages that can be queued. 3.Specifying a queue store to persist data. You achieve this fine-tuning by specifying parameters for a global processing strategy.









